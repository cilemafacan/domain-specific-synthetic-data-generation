{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 10:53:23.727716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/cilem/anaconda3/envs/path/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import openslide as ops\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from huggingface_hub import from_pretrained_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSI_DIR = \"./wsis\"\n",
    "MODEL_NAME = \"/home/cilem/.cache/huggingface/hub/models--google--path-foundation/snapshots/fd6a835ceaae15be80db6abd8dcfeb86a9287e72\"\n",
    "PATCH_DIR = \"./embeddings\"\n",
    "LOG_NAME = \"embedding_extractor.log\"\n",
    "PATCH_SIZE = 512\n",
    "OVERLAP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "                    filename=\"./logs/{}\".format(LOG_NAME))\n",
    "\n",
    "logging.info(\"Starting patch extraction...\")\n",
    "if not os.path.exists(PATCH_DIR):\n",
    "    os.makedirs(PATCH_DIR)\n",
    "\n",
    "logging.info(\"Extracting patches from WSI...\")\n",
    "logging.info(\"Patch size: {}\".format(PATCH_SIZE))\n",
    "logging.info(\"Overlap: {}\".format(OVERLAP))\n",
    "logging.info(\"WSI directory: {}\".format(WSI_DIR))\n",
    "logging.info(\"Patch directory: {}\".format(PATCH_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbeddingExtractor:\n",
    "    def __init__(self, slide_root_path, model_name, patch_size, overlap):\n",
    "        self.model = keras.layers.TFSMLayer(model_name, call_endpoint='serving_default')\n",
    "        #self.infer = self.model.signatures[\"serving_default\"]\n",
    "        self.infer = self.model\n",
    "        \n",
    "\n",
    "        self.slides_path = []\n",
    "        for root, dirs, files in os.walk(slide_root_path):\n",
    "            for file in files:\n",
    "                if file.endswith((\".svs\", \".tiff\", \".tif\")):\n",
    "                    self.slide_path = os.path.join(root, file)\n",
    "                    self.slides_path.append(self.slide_path)\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "    \n",
    "    def extract_patch_embeddings(self):\n",
    "        self.embeddings = []\n",
    "        for slide_path in self.slides_path:\n",
    "            try:\n",
    "                slide = ops.OpenSlide(slide_path)\n",
    "                slide_name = os.path.basename(slide_path)\n",
    "                slide_width, slide_height = slide.dimensions\n",
    "                patch_width, patch_height = self.patch_size\n",
    "                overlap_width, overlap_height = self.overlap\n",
    "\n",
    "                for y in range(0, slide_height, patch_height-overlap_height):\n",
    "                    for x in range(0, slide_width, patch_width-overlap_width):\n",
    "                        patch = slide.read_region(location=(x, y), level=0, size=self.patch_size)\n",
    "                        if patch.size < self.patch_size:\n",
    "                            continue\n",
    "                        else:\n",
    "                            patch_ = patch.convert(\"RGB\")\n",
    "                            patch = patch_.resize((224, 224))\n",
    "                            patch = np.array(patch)\n",
    "                            img = tf.cast(patch, tf.float32) / 255.0\n",
    "                            img = tf.expand_dims(img, 0)\n",
    "                            embedding = self.infer(tf.constant(img))[\"output_0\"].numpy()\n",
    "                            self.embeddings.append({\n",
    "                                \"slide_name\": slide_name,\n",
    "                                \"x\": x,\n",
    "                                \"y\": y,\n",
    "                                \"level\": 0,\n",
    "                                \"patch_size\": self.patch_size,\n",
    "                                \"resize\": (224, 224),\n",
    "                                \"embedding_vector\": embedding\n",
    "                            })\n",
    "                            logging.info(f\"Extracted patch embedding from {slide_path} at ({x}, {y})\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting patch embeddings from {slide_path}: {e}\")\n",
    "\n",
    "        return self.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739606018.475251  990006 service.cc:148] XLA service 0x7fe24c00b630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739606018.475310  990006 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "2025-02-15 10:53:38.645729: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1739606022.838840  990006 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "extractor = PatchEmbeddingExtractor(slide_root_path=WSI_DIR, \n",
    "                                    model_name= MODEL_NAME,\n",
    "                                    patch_size=(PATCH_SIZE, PATCH_SIZE), \n",
    "                                    overlap=(OVERLAP, OVERLAP))\n",
    "\n",
    "embeddings = extractor.extract_patch_embeddings()\n",
    "logging.info(\"Number of extracted patches: {}\".format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted patches: 890163\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted patches: {}\".format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Saving embeddings...\")\n",
    "with open(os.path.join(PATCH_DIR, f\"embeddings_{PATCH_SIZE}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "dataset = pickle.load(open(os.path.join(PATCH_DIR, f\"embeddings_{PATCH_SIZE}.pkl\"), \"rb\"))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "import tensorflow\n",
    "import keras\n",
    "print(huggingface_hub.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "from IPython.display import display\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "img = PILImage.open(\"Test.png\").crop((0, 0, 224, 224)).convert('RGB')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Compute Embeddings\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Convert the image to a Tensor and scale to [0, 1]\n",
    "tensor = tf.cast(tf.expand_dims(np.array(img), axis=0), tf.float32) / 255.0\n",
    "print(\"Tensor shape:\", type(tensor), tensor.shape)\n",
    "# Load the model directly from Hugging Face\n",
    "loaded_model = keras.layers.TFSMLayer(\"/home/cilem/.cache/huggingface/hub/models--google--path-foundation/snapshots/fd6a835ceaae15be80db6abd8dcfeb86a9287e72\", call_endpoint='serving_default')\n",
    "\n",
    "# Call inference\n",
    "infer = loaded_model\n",
    "embeddings = infer(tf.constant(tensor))\n",
    "\n",
    "# Extract the embedding vector\n",
    "embedding_vector = embeddings['output_0'].numpy()\n",
    "print(\"Size of embedding vector:\", embedding_vector.shape)\n",
    "\n",
    "# Plot the embedding vector\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(embedding_vector)\n",
    "plt.title('Embedding Vector')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
